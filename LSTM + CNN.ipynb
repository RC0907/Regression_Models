{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = ['unit_number', 'time_cycles']\n",
    "setting_names = ['opp_set_1', 'opp_set_2', 'opp_set_3']\n",
    "sensor_names = ['s_m{}'.format(i+1) for i in range(0,21)]\n",
    "col_names = index_names + setting_names + sensor_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ls/cldmn3dj6mx5c8nw38zdl7yw0000gn/T/ipykernel_14004/3696279310.py:1: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  train = pd.read_csv('/Users/rahulchauhan/Downloads/CMaps/train_FD001.txt',sep=' ', index_col=False, header=None, names=col_names)\n",
      "/var/folders/ls/cldmn3dj6mx5c8nw38zdl7yw0000gn/T/ipykernel_14004/3696279310.py:2: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  test = pd.read_csv('/Users/rahulchauhan/Downloads/CMaps/test_FD001.txt',sep = ' ',index_col= False,header=None,names = col_names)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/Users/rahulchauhan/Downloads/CMaps/train_FD001.txt',sep=' ', index_col=False, header=None, names=col_names)\n",
    "test = pd.read_csv('/Users/rahulchauhan/Downloads/CMaps/test_FD001.txt',sep = ' ',index_col= False,header=None,names = col_names)\n",
    "RUL = pd.read_csv('/Users/rahulchauhan/Downloads/CMaps/RUL_FD001.txt',sep = ' ',index_col= False,header=None,names = ['RUL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_number</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>opp_set_1</th>\n",
       "      <th>opp_set_2</th>\n",
       "      <th>opp_set_3</th>\n",
       "      <th>s_m1</th>\n",
       "      <th>s_m2</th>\n",
       "      <th>s_m3</th>\n",
       "      <th>s_m4</th>\n",
       "      <th>s_m5</th>\n",
       "      <th>...</th>\n",
       "      <th>s_m12</th>\n",
       "      <th>s_m13</th>\n",
       "      <th>s_m14</th>\n",
       "      <th>s_m15</th>\n",
       "      <th>s_m16</th>\n",
       "      <th>s_m17</th>\n",
       "      <th>s_m18</th>\n",
       "      <th>s_m19</th>\n",
       "      <th>s_m20</th>\n",
       "      <th>s_m21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_number  time_cycles  opp_set_1  opp_set_2  opp_set_3    s_m1    s_m2  \\\n",
       "0            1            1    -0.0007    -0.0004      100.0  518.67  641.82   \n",
       "1            1            2     0.0019    -0.0003      100.0  518.67  642.15   \n",
       "2            1            3    -0.0043     0.0003      100.0  518.67  642.35   \n",
       "3            1            4     0.0007     0.0000      100.0  518.67  642.35   \n",
       "4            1            5    -0.0019    -0.0002      100.0  518.67  642.37   \n",
       "\n",
       "      s_m3     s_m4   s_m5  ...   s_m12    s_m13    s_m14   s_m15  s_m16  \\\n",
       "0  1589.70  1400.60  14.62  ...  521.66  2388.02  8138.62  8.4195   0.03   \n",
       "1  1591.82  1403.14  14.62  ...  522.28  2388.07  8131.49  8.4318   0.03   \n",
       "2  1587.99  1404.20  14.62  ...  522.42  2388.03  8133.23  8.4178   0.03   \n",
       "3  1582.79  1401.87  14.62  ...  522.86  2388.08  8133.83  8.3682   0.03   \n",
       "4  1582.85  1406.22  14.62  ...  522.19  2388.04  8133.80  8.4294   0.03   \n",
       "\n",
       "   s_m17  s_m18  s_m19  s_m20    s_m21  \n",
       "0    392   2388  100.0  39.06  23.4190  \n",
       "1    392   2388  100.0  39.00  23.4236  \n",
       "2    390   2388  100.0  38.95  23.3442  \n",
       "3    392   2388  100.0  38.88  23.3739  \n",
       "4    393   2388  100.0  38.90  23.4044  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 26)\n",
      "(13096, 26)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(RUL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rul(g):\n",
    "    # Calculate the RUL as the difference between the maximum cycle value and the cycle value for each row\n",
    "    g['RUL'] = max(g['time_cycles']) - g['time_cycles']\n",
    "    return g\n",
    "\n",
    "# Apply the add_rul function to the training data grouped by the unit ID\n",
    "train_data = train.groupby('unit_number').apply(add_rul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulchauhan/Library/Python/3.9/lib/python/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/rahulchauhan/Library/Python/3.9/lib/python/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "unit_number    7.875253e-02\n",
       "time_cycles   -7.362406e-01\n",
       "opp_set_1     -3.198458e-03\n",
       "opp_set_2     -1.947628e-03\n",
       "opp_set_3               NaN\n",
       "s_m1                    NaN\n",
       "s_m2          -6.064840e-01\n",
       "s_m3          -5.845204e-01\n",
       "s_m4          -6.789482e-01\n",
       "s_m5          -5.849749e-16\n",
       "s_m6          -1.283484e-01\n",
       "s_m7           6.572227e-01\n",
       "s_m8          -5.639684e-01\n",
       "s_m9          -3.901016e-01\n",
       "s_m10                   NaN\n",
       "s_m11         -6.962281e-01\n",
       "s_m12          6.719831e-01\n",
       "s_m13         -5.625688e-01\n",
       "s_m14         -3.067689e-01\n",
       "s_m15         -6.426670e-01\n",
       "s_m16         -5.849749e-16\n",
       "s_m17         -6.061536e-01\n",
       "s_m18                   NaN\n",
       "s_m19                   NaN\n",
       "s_m20          6.294285e-01\n",
       "s_m21          6.356620e-01\n",
       "RUL            1.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.corrwith(train_data['RUL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_targets(data_length, early_rul = None):\n",
    "    if early_rul == None:\n",
    "        return np.arange(data_length-1, -1, -1)\n",
    "    else:\n",
    "        early_rul_duration = data_length - early_rul\n",
    "        if early_rul_duration <= 0:\n",
    "            return np.arange(data_length-1, -1, -1)\n",
    "        else:\n",
    "            return np.append(early_rul*np.ones(shape = (early_rul_duration,)), np.arange(early_rul-1, -1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input_data_with_targets(input_data, target_data = None, window_length = 1, shift = 1):\n",
    "    num_batches = int(np.floor((len(input_data) - window_length)/shift)) + 1\n",
    "    num_features = input_data.shape[1]\n",
    "    output_data = np.repeat(np.nan, repeats = num_batches * window_length * num_features).reshape(num_batches, window_length,\n",
    "                                                                                                  num_features)\n",
    "    if target_data is None:\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "        return output_data\n",
    "    else:\n",
    "        output_targets = np.repeat(np.nan, repeats = num_batches)\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "            output_targets[batch] = target_data[(shift*batch + (window_length-1))]\n",
    "        return output_data, output_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data(test_data_for_an_engine, window_length, shift, num_test_windows = 1):\n",
    "  \n",
    "    max_num_test_batches = int(np.floor((len(test_data_for_an_engine) - window_length)/shift)) + 1\n",
    "    if max_num_test_batches < num_test_windows:\n",
    "        required_len = (max_num_test_batches -1)* shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length= window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, max_num_test_batches\n",
    "    else:\n",
    "        required_len = (num_test_windows - 1) * shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length= window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, num_test_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/Users/rahulchauhan/Downloads/CMaps/test_FD001.txt', sep = \"\\s+\", header = None,names=col_names )\n",
    "true_rul = pd.read_csv('/Users/rahulchauhan/Downloads/CMaps/RUL_FD001.txt', sep = '\\s+', header = None)\n",
    "\n",
    "window_length = 30\n",
    "shift = 1\n",
    "early_rul = 125           \n",
    "processed_train_data = []\n",
    "processed_train_targets = []\n",
    "num_test_windows = 5     \n",
    "processed_test_data = []\n",
    "num_test_windows_list = []\n",
    "\n",
    "columns_to_be_dropped = ['unit_number','opp_set_1','opp_set_2','opp_set_3','s_m1','s_m5','s_m6','s_m7','s_m10','s_m16','s_m18','s_m19']\n",
    "\n",
    "train_data_first_column = train [\"unit_number\"]\n",
    "test_data_first_column = test_data[\"unit_number\"]\n",
    "num_train_windows = (len(train) - window_length) // shift + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_number</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>opp_set_1</th>\n",
       "      <th>opp_set_2</th>\n",
       "      <th>opp_set_3</th>\n",
       "      <th>s_m1</th>\n",
       "      <th>s_m2</th>\n",
       "      <th>s_m3</th>\n",
       "      <th>s_m4</th>\n",
       "      <th>s_m5</th>\n",
       "      <th>...</th>\n",
       "      <th>s_m12</th>\n",
       "      <th>s_m13</th>\n",
       "      <th>s_m14</th>\n",
       "      <th>s_m15</th>\n",
       "      <th>s_m16</th>\n",
       "      <th>s_m17</th>\n",
       "      <th>s_m18</th>\n",
       "      <th>s_m19</th>\n",
       "      <th>s_m20</th>\n",
       "      <th>s_m21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_number  time_cycles  opp_set_1  opp_set_2  opp_set_3    s_m1    s_m2  \\\n",
       "0            1            1    -0.0007    -0.0004      100.0  518.67  641.82   \n",
       "1            1            2     0.0019    -0.0003      100.0  518.67  642.15   \n",
       "2            1            3    -0.0043     0.0003      100.0  518.67  642.35   \n",
       "3            1            4     0.0007     0.0000      100.0  518.67  642.35   \n",
       "4            1            5    -0.0019    -0.0002      100.0  518.67  642.37   \n",
       "\n",
       "      s_m3     s_m4   s_m5  ...   s_m12    s_m13    s_m14   s_m15  s_m16  \\\n",
       "0  1589.70  1400.60  14.62  ...  521.66  2388.02  8138.62  8.4195   0.03   \n",
       "1  1591.82  1403.14  14.62  ...  522.28  2388.07  8131.49  8.4318   0.03   \n",
       "2  1587.99  1404.20  14.62  ...  522.42  2388.03  8133.23  8.4178   0.03   \n",
       "3  1582.79  1401.87  14.62  ...  522.86  2388.08  8133.83  8.3682   0.03   \n",
       "4  1582.85  1406.22  14.62  ...  522.19  2388.04  8133.80  8.4294   0.03   \n",
       "\n",
       "   s_m17  s_m18  s_m19  s_m20    s_m21  \n",
       "0    392   2388  100.0  39.06  23.4190  \n",
       "1    392   2388  100.0  39.00  23.4236  \n",
       "2    390   2388  100.0  38.95  23.3442  \n",
       "3    392   2388  100.0  38.88  23.3739  \n",
       "4    393   2388  100.0  38.90  23.4044  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_data = scaler.fit_transform(train.drop(columns = columns_to_be_dropped))\n",
    "test_data = scaler.transform(test_data.drop(columns = columns_to_be_dropped))\n",
    "\n",
    "train_data = pd.DataFrame(data = np.c_[train_data_first_column, train_data])\n",
    "test_data = pd.DataFrame(data = np.c_[test_data_first_column, test_data])\n",
    "\n",
    "num_train_machines = len(train_data[0].unique())\n",
    "num_test_machines = len(test_data[0].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(1, num_train_machines + 1):\n",
    "    temp_train_data = train_data[train_data[0] == i].drop(columns=[0]).values\n",
    "    \n",
    "    # Determine whether it is possible to extract training data with the specified window length.\n",
    "    if len(temp_train_data) < window_length:\n",
    "        print(f\"Train engine {i} doesn't have enough data for window_length of {window_length}\")\n",
    "        raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n",
    "                             \"Try decreasing window length.\")\n",
    "        \n",
    "    temp_train_targets = process_targets(data_length=temp_train_data.shape[0], early_rul=early_rul)\n",
    "    data_for_a_machine, targets_for_a_machine = process_input_data_with_targets(temp_train_data, temp_train_targets, \n",
    "                                                                                window_length=window_length, shift=shift)\n",
    "    \n",
    "    processed_train_data.append(data_for_a_machine)\n",
    "    processed_train_targets.append(targets_for_a_machine)\n",
    "\n",
    "# Concatenate processed data and targets into numpy arrays\n",
    "processed_train_data = np.concatenate(processed_train_data)\n",
    "processed_train_targets = np.concatenate(processed_train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(1, num_test_machines + 1):\n",
    "    temp_test_data = test_data[test_data[0] == i].drop(columns = [0]).values\n",
    "    \n",
    "    # Determine whether it is possible to extract test data with the specified window length.\n",
    "    if (len(temp_test_data) < window_length):\n",
    "        print(\"Test engine {} doesn't have enough data for window_length of {}\".format(i, window_length))\n",
    "        raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n",
    "                             \"Try decreasing window length.\")\n",
    "    \n",
    "    # Prepare test data\n",
    "    test_data_for_an_engine, num_windows = process_test_data(temp_test_data, window_length=window_length, shift = shift,\n",
    "                                                             num_test_windows = num_test_windows)\n",
    "    \n",
    "    processed_test_data.append(test_data_for_an_engine)\n",
    "    num_test_windows_list.append(num_windows)\n",
    "\n",
    "processed_test_data = np.concatenate(processed_test_data)\n",
    "true_rul = true_rul[0].values\n",
    "\n",
    "# Shuffle training data\n",
    "index = np.random.permutation(len(processed_train_targets))\n",
    "processed_train_data, processed_train_targets = processed_train_data[index], processed_train_targets[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed trianing data shape:  (17731, 30, 14)\n",
      "Processed training ruls shape:  (17731,)\n",
      "Processed test data shape:  (497, 30, 14)\n",
      "True RUL shape:  (100,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Processed trianing data shape: \", processed_train_data.shape)\n",
    "print(\"Processed training ruls shape: \", processed_train_targets.shape)\n",
    "print(\"Processed test data shape: \", processed_test_data.shape)\n",
    "print(\"True RUL shape: \", true_rul.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed train data shape:  (14184, 30, 14)\n",
      "Processed validation data shape:  (3547, 30, 14)\n",
      "Processed train targets shape:  (14184,)\n",
      "Processed validation targets shape:  (3547,)\n"
     ]
    }
   ],
   "source": [
    "processed_train_data, processed_val_data, processed_train_targets, processed_val_targets = train_test_split(processed_train_data,\n",
    "                                                                                                            processed_train_targets,\n",
    "                                                                                                            test_size = 0.2,\n",
    "                                                                                                            random_state = 83)\n",
    "print(\"Processed train data shape: \", processed_train_data.shape)\n",
    "print(\"Processed validation data shape: \", processed_val_data.shape)\n",
    "print(\"Processed train targets shape: \", processed_train_targets.shape)\n",
    "print(\"Processed validation targets shape: \", processed_val_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulchauhan/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense,Dropout,Conv1D,MaxPooling1D,LSTM,Flatten,BatchNormalization,Bidirectional\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import legacy\n",
    "\n",
    "# Use legacy Adam optimizer\n",
    "optimizer = legacy.Adam(learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "kernel_size = 3\n",
    "model = Sequential()\n",
    "intput_shape=(window_length, processed_train_data.shape[2])\n",
    "model.add(Conv1D(128, kernel_size=kernel_size, padding = \"same\", activation=\"relu\", input_shape = intput_shape))\n",
    "model.add(Dropout(0))\n",
    "model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "model.add(Conv1D(128,kernel_size=kernel_size, padding = \"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0))\n",
    "model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(units = 128, return_sequences=True))\n",
    "model.add(LSTM(units = 128, return_sequences=False))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/10\n",
      "222/222 - 5s - loss: 2031.6490 - val_loss: 323.2769 - lr: 0.0010 - 5s/epoch - 25ms/step\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 2/10\n",
      "222/222 - 4s - loss: 247.6604 - val_loss: 193.8854 - lr: 0.0010 - 4s/epoch - 18ms/step\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/10\n",
      "222/222 - 4s - loss: 184.0537 - val_loss: 161.0054 - lr: 0.0010 - 4s/epoch - 17ms/step\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/10\n",
      "222/222 - 4s - loss: 153.5699 - val_loss: 123.8733 - lr: 0.0010 - 4s/epoch - 16ms/step\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 5/10\n",
      "222/222 - 3s - loss: 127.0340 - val_loss: 108.9916 - lr: 0.0010 - 3s/epoch - 16ms/step\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 6/10\n",
      "222/222 - 4s - loss: 91.6312 - val_loss: 76.1442 - lr: 1.0000e-04 - 4s/epoch - 16ms/step\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 7/10\n",
      "222/222 - 4s - loss: 85.9353 - val_loss: 71.3579 - lr: 1.0000e-04 - 4s/epoch - 17ms/step\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 8/10\n",
      "222/222 - 4s - loss: 80.7930 - val_loss: 66.5499 - lr: 1.0000e-04 - 4s/epoch - 16ms/step\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 9/10\n",
      "222/222 - 4s - loss: 77.5828 - val_loss: 63.2235 - lr: 1.0000e-04 - 4s/epoch - 16ms/step\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 10/10\n",
      "222/222 - 4s - loss: 74.3735 - val_loss: 62.0430 - lr: 1.0000e-04 - 4s/epoch - 18ms/step\n"
     ]
    }
   ],
   "source": [
    "def scheduler(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose = 1)\n",
    "#model = create_compiled_model()\n",
    "history = model.fit(processed_train_data, processed_train_targets, epochs = 10,\n",
    "                    validation_data = (processed_val_data, processed_val_targets),\n",
    "                    callbacks = callback,\n",
    "                    batch_size = 64, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 30, 128)           5504      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 30, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 15, 128)           0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 15, 128)           49280     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 15, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 8, 128)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 8, 128)            0         \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 8, 128)            131584    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               25800     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 343953 (1.31 MB)\n",
      "Trainable params: 343953 (1.31 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 3ms/step\n",
      "RMSE:  14.488865032397364\n"
     ]
    }
   ],
   "source": [
    "rul_pred = model.predict(processed_test_data).reshape(-1)\n",
    "preds_for_each_engine = np.split(rul_pred, np.cumsum(num_test_windows_list)[:-1])\n",
    "mean_pred_for_each_engine = [np.average(ruls_for_each_engine, weights = np.repeat(1/num_windows, num_windows)) \n",
    "                             for ruls_for_each_engine, num_windows in zip(preds_for_each_engine, num_test_windows_list)]\n",
    "RMSE = np.sqrt(mean_squared_error(true_rul, mean_pred_for_each_engine))\n",
    "print(\"RMSE: \", RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Taking only last examples):  15.288546948503276\n"
     ]
    }
   ],
   "source": [
    "indices_of_last_examples = np.cumsum(num_test_windows_list) - 1\n",
    "preds_for_last_example = np.concatenate(preds_for_each_engine)[indices_of_last_examples]\n",
    "\n",
    "RMSE_new = np.sqrt(mean_squared_error(true_rul, preds_for_last_example))\n",
    "print(\"RMSE (Taking only last examples): \", RMSE_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-score:  343.9804326854027\n"
     ]
    }
   ],
   "source": [
    "def compute_s_score(rul_true, rul_pred):\n",
    "    \"\"\"\n",
    "    Both rul_true and rul_pred should be 1D numpy arrays.\n",
    "    \"\"\"\n",
    "    diff = rul_pred - rul_true\n",
    "    return np.sum(np.where(diff < 0, np.exp(-diff/13)-1, np.exp(diff/10)-1))\n",
    "s_score = compute_s_score(true_rul, preds_for_last_example)\n",
    "print(\"S-score: \", s_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_compiled_model(lr=0.001, drop_CNN=0, drop_dense=0.2, kernel_size=3):\n",
    "    model = Sequential()\n",
    "    intput_shape=(window_length, processed_train_data.shape[2])\n",
    "    model.add(Conv1D(128, kernel_size=kernel_size, padding = \"same\", activation=\"relu\", input_shape = intput_shape))\n",
    "    model.add(Dropout(drop_CNN))\n",
    "    model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "    model.add(Conv1D(128,kernel_size=kernel_size, padding = \"same\", activation=\"relu\"))\n",
    "    model.add(Dropout(drop_CNN))\n",
    "    model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(units = 128, return_sequences=True))\n",
    "    model.add(LSTM(units = 128, return_sequences=False))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dropout(drop_CNN))\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/10\n",
      "222/222 - 5s - loss: 2317.7764 - val_loss: 1779.7469 - lr: 0.0010 - 5s/epoch - 23ms/step\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 2/10\n",
      "222/222 - 4s - loss: 732.1054 - val_loss: 264.7200 - lr: 0.0010 - 4s/epoch - 17ms/step\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/10\n",
      "222/222 - 4s - loss: 179.8972 - val_loss: 163.8669 - lr: 0.0010 - 4s/epoch - 16ms/step\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/10\n",
      "222/222 - 4s - loss: 136.0746 - val_loss: 156.7845 - lr: 0.0010 - 4s/epoch - 17ms/step\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 5/10\n",
      "222/222 - 4s - loss: 103.8050 - val_loss: 95.2464 - lr: 0.0010 - 4s/epoch - 17ms/step\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 6/10\n",
      "222/222 - 4s - loss: 66.5498 - val_loss: 76.7227 - lr: 1.0000e-04 - 4s/epoch - 18ms/step\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 7/10\n",
      "222/222 - 4s - loss: 59.7526 - val_loss: 68.6172 - lr: 1.0000e-04 - 4s/epoch - 18ms/step\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 8/10\n",
      "222/222 - 4s - loss: 55.5297 - val_loss: 67.3714 - lr: 1.0000e-04 - 4s/epoch - 17ms/step\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 9/10\n",
      "222/222 - 4s - loss: 52.0994 - val_loss: 62.4501 - lr: 1.0000e-04 - 4s/epoch - 17ms/step\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 10/10\n",
      "222/222 - 4s - loss: 48.7332 - val_loss: 59.2085 - lr: 1.0000e-04 - 4s/epoch - 18ms/step\n"
     ]
    }
   ],
   "source": [
    "def scheduler(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose = 1)\n",
    "model = create_compiled_model()\n",
    "history = model.fit(processed_train_data, processed_train_targets, epochs = 10,\n",
    "                    validation_data = (processed_val_data, processed_val_targets),\n",
    "                    callbacks = callback,\n",
    "                    batch_size = 64, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step\n",
      "RMSE:  14.637747972796554\n"
     ]
    }
   ],
   "source": [
    "rul_pred = model.predict(processed_test_data).reshape(-1)\n",
    "preds_for_each_engine = np.split(rul_pred, np.cumsum(num_test_windows_list)[:-1])\n",
    "mean_pred_for_each_engine = [np.average(ruls_for_each_engine, weights = np.repeat(1/num_windows, num_windows)) \n",
    "                             for ruls_for_each_engine, num_windows in zip(preds_for_each_engine, num_test_windows_list)]\n",
    "RMSE = np.sqrt(mean_squared_error(true_rul, mean_pred_for_each_engine))\n",
    "print(\"RMSE: \", RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loss_RMSE  val_loss_RMSE\n",
      "0      48.14          42.19\n",
      "1      27.06          16.27\n",
      "2      13.41          12.80\n",
      "3      11.67          12.52\n",
      "4      10.19           9.76\n",
      "5       8.16           8.76\n",
      "6       7.73           8.28\n",
      "7       7.45           8.21\n",
      "8       7.22           7.90\n",
      "9       6.98           7.69\n"
     ]
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Converting MSE to RMSE\n",
    "loss_rmse = [round(val ** 0.5,2) for val in loss]\n",
    "val_loss_rmse = [round(val ** 0.5,2) for val in val_loss]\n",
    "\n",
    "# Creating a DataFrame\n",
    "loss_df = pd.DataFrame({'loss_RMSE': loss_rmse, 'val_loss_RMSE': val_loss_rmse})\n",
    "output = '/Users/rahulchauhan/Documents/IIT_G/MTP/LSTM + CNN Series/FD001.csv'\n",
    "loss_df.to_csv(output,index = False)\n",
    "# Printing the DataFrame\n",
    "print(loss_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x32b364fa0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],label ='Training Loss')\n",
    "plt.plot(history.history['val_loss'],label = 'Validation Loss')\n",
    "plt.title('Training and Validation Loss over epochs for FD001')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
